---
title: "Assigning ASVs with DADA2"
author: "Chloe J. McGovern"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
    code_folding: show
    theme: spacelab
    highlight: pygments
    keep_md: no
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 3
  keep_md: true  
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      #Send figures generated in this file to the folder below
                      fig.path = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/figures/02_Assign_ASVs/") 
```

#Goals

1. Infer errors in the sequences, separately on the forward and reverse reads.
2. Assign ASVs on both the forward and reverse reads, separately. Apply the error model. 
3. Merge the forward and reverse ASVs into "contiguous ASVs".
4. Generate our first draft of our ASV count table. 
5. Quality trimming of ASV lengths.
6. Remove chimeras.
7. Assign Taxonomy with Silva Database.
. Write out relevant files: `asv_table` , `asvs_fasta` , and `sample_data` . 

#Input

1. Filtered fastq files generated from `01_QualityTrimming.Rmd`
2. Sample Name vector.

##Output
1. `asv_table`
2. `asvs_fasta`
3. `tax_table`
4. `sample_data`

#Set up the environment

## Set the seed
```{r, set-seed}
#reproducibility
set.seed(6572)

#Parameter for thread number
n_threads = 20

```

#Timing the script
This will tell us how long it took to run the file on the class server.

```{r time}
start_time <- Sys.time()
```


## Load packages
```{r load-packages}
pacman::p_load(tidyverse, devtools, dada2, 
               patchwork, DT, install=FALSE)

```

#Load filtered Fastq files
```{r load-filtered-fastqs}
# Place filtered seq files into a variable 
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# Intuition check:
filtered_fastqs_path

#Create forward vector
filtered_forward_reads <-
  list.files(filtered_fastqs_path, pattern = "R1_filtered.fastq.gz" , 
             full.names = TRUE)

#Check
filtered_forward_reads[1:5]

#Reverse vector
filtered_reverse_reads <-
  list.files(filtered_fastqs_path, pattern = "R2_filtered.fastq.gz" , 
             full.names = TRUE)

#Check
filtered_reverse_reads

```

#Assign sample names

```{r sample-names}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(filtered_forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)
```

# Error modeling

```{r learn-errors}
#Forward Reads
error_forward_reads <-
  learnErrors(filtered_forward_reads, multithread = n_threads)

#Plot
forward_error_plot <-
  plotErrors(error_forward_reads, nominalQ = TRUE) +
  labs(title = "Forward Error Model")

#Reverse Reads
error_reverse_reads <-
  learnErrors(filtered_reverse_reads, multithread = n_threads)

#Plot
reverse_error_plot <-
  plotErrors(error_reverse_reads, nominalQ = TRUE) +
  labs(title = "Reverse Error Reads")

#Look at the plots together
err_plot <- forward_error_plot + reverse_error_plot

ggsave("err_plot.png", plot = err_plot, width = 8, height = 6, dpi = 300)
getwd()

```

#Infer sequencing reads

```{r infer-ASVs}
# Infer ASVs on the forward sequences
dada_forward <- 
  dada(filtered_forward_reads,
        err = error_forward_reads, 
        multithread = n_threads)

# Take a look at the data
typeof(dada_forward)
length(dada_forward)
dada_forward$`SRR9722160_R1_filtered.fastq.gz`


#Reverse ASVs
dada_reverse <-
  dada(filtered_reverse_reads,
       err = error_reverse_reads,
       multithread = n_threads)

#Take a look
typeof(dada_reverse)
dada_reverse[10]

```


# Merge Forward and Reverse ASVs

```{r merge-ASVs}
merged_ASVs <-
  mergePairs(dada_forward, filtered_forward_reads,
             dada_reverse, filtered_reverse_reads,
             verbose = TRUE)

#Evaluate the data output
typeof(merged_ASVs)
length (merged_ASVs)
names(merged_ASVs)
head(merged_ASVs[[3]])
head(names(merged_ASVs))

# Inspect further for each sample
#head(merged_ASVs, n = 2) # A dataframe for each sample
# We have a dataframe in each part of our list! What are in the columns? 
glimpse(merged_ASVs$`SRR9722160_R1_filtered.fastq.gz`)
```



#Create Raw ASV Count Table

```{r raw-ASV-count-table}
raw_ASV_table <- makeSequenceTable(merged_ASVs)

#Check
dim(raw_ASV_table)
typeof(raw_ASV_table)
class(raw_ASV_table)

# Write out the raw ASV table
write.table(raw_ASV_table, file = "data/01_DADA2/raw_ASV_counts.tsv" , 
            sep = "\t" , quote = FALSE, col.names = NA)

```

##Interpretation 1: 

###What are the current ASV lengths?

The sequencing strategy reported for this data set was as follows;

-Illumina MiSeq System with a paired-end v2 500-cycles kit (which is the same as 2x250pb)
-Specifically amplifying the V4 domain of bacterial 16S rRNA gene using F515 and R806 primers, both modified to contain an Illumina adapter region

The total length (including primers) for this starting amplicon data set is 291 bps. We get this from subtracting the 806R from the 515F primers. 

The Earth Microbiome Project outlined that the 515F primer is 19 bps and the 806R is 20 bps. Therefor subtracting those lengths from the 291 total bps was 252 total bps. These were truncated from the raw fastq files in the 01_QualityTrimming data set. 

After the filter and trim, there are 185bps which provided the best percentage of sequences retained. The primers were included in the data, so the first 19 bps from the forward reads and the last 20 bps for the reverse files were removed, so our total base pairs were 185. 

The overlap of the forward and reverse reads is 100% because 250 bps were in the forward and reverse and 252 bps were in the read after the primers were trimmed out. 

# Asses the ASV length

Some more QC!

```{r assess-ASV-length}

# Calculate summary stats
# Longest ASV?
maxLength_ASV <- max(nchar(getSequences(raw_ASV_table))) 

# Shortest ASV?
minLength_ASV <- min(nchar(getSequences(raw_ASV_table))) 

# Mean ASV length?
meanLength_ASV <- mean(nchar(getSequences(raw_ASV_table)))

# Median ASV length?
medianLength_ASV <- median(nchar(getSequences(raw_ASV_table))) 

# Create a table to Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table)))
  
```


#ASV Length Plot
```{r ASV-length-plot}
# Inspect the distribution of sequence lengths of all ASVs in data set 
# AFTER TRIM
plot_ASVLength_raw <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Raw ASV Length (bps)")

# Show the plot
plot_ASVLength_raw
```

##Interpretation 2: 

As we saw in the table, the length of the ASVs are 298 sequences that are 252 bps long and 490 sequences that are 253 bps long. This plot does confirm my hypothesis from Interpretation 1! All of the sequences retained were at (or one above) the expected bps length. Therefore, yes this matches my hypothesis for question 1 that the actual ASV length meets the expectations. 

##Interpretation 3: 

I decided I am not going to trim this data set because the sequence lengths are binned at 252 and 253 bps. I think they are close enough--with enough reads in each bin, to keep all the samples. 

# Trim ASVs

```{r trim-ASVs}
#Only pull ASVs that have a length of 245 bps
raw_ASV_table_trimmed <- raw_ASV_table[, nchar(getSequences(raw_ASV_table)) %in% c(252, 253)]

#Intuition check
table(nchar(getSequences(raw_ASV_table_trimmed)))

# What proportion of total ASV sequences are left in the data? 
percRetained_Trimmed <- sum(raw_ASV_table_trimmed)/sum(raw_ASV_table)
percRetained_Trimmed 

# Inspect the distribution of sequence lengths of all ASVs in dataset 
# AFTER TRIM
plot_ASVLength_trimmed <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table_trimmed))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Trimmed ASV Length (bps)")

# Show the plot 
plot_ASVLength_trimmed
  
```

#Remove Chimeras

```{r remove-chimeras}
# Remove the chimeras in the raw ASV table
noChimeras_ASV_table <- removeBimeraDenovo(raw_ASV_table_trimmed, 
                                           method="consensus", 
                                           multithread=TRUE, verbose=TRUE)

# Check the dimensions
dim(noChimeras_ASV_table)
dim(raw_ASV_table_trimmed)
#Difference tells us how many were cut from chimeras

# What proportion is left of the sequences? 
percRetained_chimerasTrimmed <- sum(noChimeras_ASV_table)/sum(raw_ASV_table_trimmed)

percRetained_chimerasRaw <-sum(noChimeras_ASV_table)/sum(raw_ASV_table)

# Plot it 
plot_ASVLength_NoChimeras <- 
  data.frame(Seq_Length_NoChim = nchar(getSequences(noChimeras_ASV_table))) %>%
  ggplot(aes(x = Seq_Length_NoChim )) + 
  geom_histogram()+ 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs \n (Post-Chimera Removal)", 
       x = "ASV Length (bps)")

# Show the plot
plot_ASVLength_NoChimeras 
```

##Interpretation 4:

There was 100% retention of ASVs after trimming because no sequences were trimmed! (per interpretation 3)

In the original raw ASV trimmed file, there were 788 sequences. After chimera removal there are 93. That is an 11.8% retention rate in ASVs after chimera removal which is very low. 

Since no sequences were trimmed, this equates to an overall retention rate od 11.8% retention of ASVs after both filtering (even though there was no filtering) and chimera  removal. 

#Plot ASV Lengths

```{r plot-ASV-length}

plot_ASVLength_raw + plot_ASVLength_trimmed + plot_ASVLength_NoChimeras + 
    plot_annotation(tag_levels = 'A')

```

#Track the read counts

```{r track-read-counts}

# A little function to identify number seqs 
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs 
track <- cbind(sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_ASVs, getN),
               rowSums(noChimeras_ASV_table))

head(track)

# Update column names to be more informative (most are missing at the moment!)
colnames(track) <- c("denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- row.names(noChimeras_ASV_table)

# Generate a dataframe to track the reads through our DADA2 pipeline
track_counts_df <- 
  track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var = "sample_names")

# Now let's add a column for the number of ASVs
# First, intuition check that the samples match 
stopifnot(track_counts_df$sample_names == row.names(noChimeras_ASV_table))

# Now, let's add a new column with the number of ASVs
track_counts_df <- 
  track_counts_df %>%
  mutate(num_ASVs = rowSums(noChimeras_ASV_table > 1))

# Visualize it in table format 
DT::datatable(track_counts_df)

# Plot it!
track_counts_df %>%
  pivot_longer(denoisedF:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  geom_line(aes(group = sample_names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Filtering Step", y = "Number of Sequences") + 
  theme_bw()

plot_ReadDepth <- 
  track_counts_df %>%
  ggplot(aes(x = nochim)) + 
  geom_histogram() + 
  labs(x = "Total # of Sequences", y = "# of Samples") + 
  theme_bw()

# What is the ASV richness per sample? 
plot_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = num_ASVs)) + 
  geom_histogram() + 
  labs(x = "Total # of ASVs", y = "# of Samples") + 
  theme_bw()

# Now, let's look at the relationship of ASVs and Sequencing depth 
plot_ReadDepth_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = nochim, y = num_ASVs)) + 
  geom_point() + 
  labs(x = "Total # of Sequences", y = "# of ASVs") + 
  theme_bw()

# Show the plots together 
plot_ReadDepth + plot_ASVRichness + plot_ReadDepth_ASVRichness + 
    plot_annotation(tag_levels = 'A')

```

##Interpretation 5:

###Panel A : Read Depth After DADA2

-X-axis: Total number of sequences per sample (after filtering).
-Y-axis: Number of samples with that read depth.

Looking at this graph, there is no real trend visible from the histogram. This can tell us a few things such as there are a lot of variability in sequencing depth across the samples. Some reads have over 60,000 reads and others have very low sequencing depth. This is important to know for down stream analysis that the data may not be reliable for diversity analysis. These problems could have stemmed from issues in the wet-lab with DNA extractions, PCR amplifications, or in the sequencing run. 

###Panel B : ASV Richness After DADA2

-X-axis: Total number of ASVs per sample (unique amplicon sequence variants).
-Y-axis: Number of samples with that ASV richness.

Like figure A, figure B has no clear distribution in the histogram. Most samples have low ASV richness (~10-30 ASVs per sample) and only a few samples have higher richenss which suggests that the samples have low microbial diversity--which checks out being that it is limited to Brazilian cheese samples. These differences in richness could potentially correspond with the meta data of cheese type. 


###Panel C : Read Depth vs ASV Richness

-X-axis: Total number of sequences per sample.
-Y-axis: Total number of ASVs detected.

While not a completely linear relationship, there does to be a positive relationship between read depth and ASV richness. Some high-read samples have low ASV richness. They may be dominated by a few species. For future analysis, rarefaction and the fact that there may be some dominant species may be important to remember when doing diversity metrics. 

#Assigning Taxonomy

```{r assigning-taxonomy}
# Assign up to genus level 
taxa_train <- 
  assignTaxonomy(noChimeras_ASV_table, 
                 refFasta = "/local/workdir/in_class_data/taxonomy/silva_nr99_v138.2_toGenus_trainset.fa.gz", 
                 multithread = n_threads)

# Add the genus/species information 
taxa_addSpecies <- 
  addSpecies(taxa_train, 
              refFasta = "/local/workdir/in_class_data/taxonomy/silva_v138.2_assignSpecies.fa.gz")

# Inspect the taxonomy 
glimpse(taxa_addSpecies) # Note that the rownames are the ASV sequences!

# Let's removing the ASV sequence rownames for display only
taxa_print <- taxa_addSpecies 
rownames(taxa_print) <- NULL
head(taxa_print)

#View(taxa_print)

```

#Export the data

##1. ASV Tables 

We will export the following two ASV count tables, which will be in “long” format where the ASVs are in rows and the sample names are in the columns.

With ASV seqs: ASV headers include the entire ASV sequence 245 bases.
with ASV names: This includes re-written and shortened headers like ASV_1, ASV_2, etc, which will match the names in our fasta file below.

###Structure of ASVs

Let’s check that the ASVs are in the rows and the sample names are in the columns. If not, we can use the transpose function t() in R.

```{r structure-ASVs}

# What's the current format of the ASV table?
head(rownames(noChimeras_ASV_table)) # Samples!

head(colnames(noChimeras_ASV_table)) # ASV Sequences

# Therefore, we need to transpose the matrix 
final_ASV_table_withSeqs <- t(noChimeras_ASV_table)

# Intuition check
head(rownames(final_ASV_table_withSeqs)) # ASV Sequences

head(colnames(final_ASV_table_withSeqs)) # Sample names

```

###Names in ASV Tables

Fix Sample Names

```{r name-ASVs}
# Remember at the top of the file we created a vector of sample names 
head(sample_names)

# Let's check with the actual column names 
head(colnames(final_ASV_table_withSeqs)) # Sample names

# And then apply our sample name script to check, too
head(sapply(strsplit(colnames(final_ASV_table_withSeqs), "_"), `[`,1)) # Looks good! 

# Now, add a break in the script break if this isn't true! 
# Let's make sure the sample names match the file names in the matrix.
stopifnot(sapply(strsplit(colnames(final_ASV_table_withSeqs), "_"), `[`,1) == sample_names)

# Now, we've done some checks to prove to ourselves there will be no silent errors, 
# Let's rename! 
colnames(final_ASV_table_withSeqs) <- sample_names
head(colnames(final_ASV_table_withSeqs))
```

###Rename ASVs

Then, we can also fix the names of our ASVs for our second ASV table where we will replace the ASV sequence names with ASV_1, ASV_2 .

```{r rename-ASVs}

# Give headers more manageable names
# First pull the ASV sequences from the rownames
ASV_seqs <- rownames(final_ASV_table_withSeqs)
ASV_seqs[1:5]

# How many ASVs? 
num_ASVs <- dim(final_ASV_table_withSeqs)[1] # select the number of rows
num_ASVs 

# Make an empty vector the length of the number of ASVs, 
# which is where we will place the new operational ASV names 
ASV_headers <- vector(num_ASVs, mode = "character")

# Let's mae sure we have an empty vector!
ASV_headers[1:5]

length(ASV_headers) # looks good! 

# Now, let's create a vector with ASV numbers
# loop through vector and fill it in with ASV names 
for (i in 1:num_ASVs) {
  # Add leading zero to ASV name so they print in correct order.
  ASV_number <- sprintf("%04d", i)
  # Now, rename each spot in the ASV header vector as we loop through the for loop
  ASV_headers[i] <- paste(">ASV", ASV_number, sep = "_")
}

# Intuition check
ASV_headers[1:5]

# Create a new ASV table, which will have the ASV numbers as names 
# View(noChimeras_ASV_table) # To view the table
final_ASV_table <- final_ASV_table_withSeqs
glimpse(final_ASV_table)

## Replace the ASV seqs with the ASV numbers 
row.names(final_ASV_table) <- sub(">", "", ASV_headers)
final_ASV_table[1:5, 1:5]

#View(final_ASV_table) # To view the table
```

###Write the ASV Tables

1. With ASV seqs: ASV headers include the entire ASV sequence 245 bases.
2. With ASV names: This includes re-written and shortened headers like ASV_1, ASV_2, etc, which will match the names in our fasta file below.

```{r write-ASV-table}

# 1. Write count table with ASV sequence names
write.table(final_ASV_table_withSeqs, 
            file = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/01_DADA2/ASV_table_withSeqNames.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

# 2. Write count table with ASV numbered names (e.g. ASV_1, ASV_2, etc)
write.table(final_ASV_table, 
            file = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/01_DADA2/ASV_table.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)

```

## 2. ASV FASTA File

Now, let’s create a fasta file that has our ASV numbers with each of their corresponding ASV sequences. This file needs to be created because we will use it later to build a phylogenetic tree.

###Write the ASV Fasta File

```{r write-ASV-fasta-file}
 # Let's take our asv_headers
head(ASV_headers, n = 2)

head(ASV_seqs, n = 2)

# Combine in a fasta format with the cbind() function
ASV_fasta <- c(rbind(ASV_headers, ASV_seqs))
head(ASV_fasta, n = 4)

# Then, let's write it to a fasta file!
# This will be our reference later on for which seq matches which ASV
write(ASV_fasta, "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/01_DADA2/ASVs.fasta")

```

## 3. Taxonomy Table

Before we actually write the taxonomy table, let’s put the ASV sequences as another column in our taxonomy table and then replace the rownames to be our numbered ASV names.

###Refortmat Taxonomy

1. Move ASV sequences to column
2. Replace ASV row names with ASV numbered names

```{r reformat-taxonomy}
# Inspect the taxonomy table
dim(taxa_addSpecies) # ASVs are in rows and Kingdom, Phylum, etc in Columns

colnames(taxa_addSpecies) # Column names are Linnean Taxonomy 

head(rownames(taxa_addSpecies), n = 2) # ASV names are rownames 

class(taxa_addSpecies) # Character matrix

##### Prepare tax table 
# 1. Add the ASV sequences from the rownames to a column 
new_tax_table <- 
  taxa_addSpecies%>%
  as.data.frame() %>%
  rownames_to_column(var = "ASVseqs") 

# Intuition check 
glimpse(new_tax_table)

# IMPORTANT! Let's do our intuition check 
# This is where we ensure we don't mix up the ASV names!
stopifnot(new_tax_table$ASVseqs == rownames(final_ASV_table_withSeqs))

# Now let's add the ASV names 
rownames(new_tax_table) <- rownames(final_ASV_table)
head(new_tax_table)

### Final prep of tax table. Add new column with ASV names 
ASV_tax_table <- 
  new_tax_table %>%
  # add rownames from count table for phyloseq handoff
  mutate(ASV = rownames(final_ASV_table)) %>%
  # Reorder the columns
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

# Assign the rownames, which is required by phyloseq
rownames(ASV_tax_table) <- ASV_tax_table$ASV

# Take a quick look
glimpse(ASV_tax_table)

# Intution check
stopifnot(ASV_tax_table$ASV == rownames(ASV_tax_table), 
          rownames(ASV_tax_table) == rownames(ASV_tax_table))

```

### Write the Taxonomy Table

Now, let's write out the taxonomy table. 

```{r taxonomy-table}
# Write the table 
write.table(ASV_tax_table, 
            file = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/01_DADA2/ASV_taxonomy.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)
```

## 4. Sample Data

Let’s save the track_counts_df, which can be useful for downstream analyses.

```{r sample-data}
# And save the track_counts_df a R object, which we will merge with metadata information in the next step of the analysis in nalysis/02_Taxonomic_Assignment. 
save(track_counts_df, file = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/01_DADA2/track_read_counts.RData")
```

# Session Information for Reproducibility

```{r}

#Time at the end of the script
end_time <- Sys.time()
end_time 

#Echo the elapsed time
elapsed_time <- round((end_time - start_time), 3)
elapsed_time

# Ensure reproducibility with package version information
devtools::session_info()

```

