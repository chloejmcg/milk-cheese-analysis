---
title: "Quality Control: Filtering & Trimming Brazilian Cheese Amplicon Sequences"
author: "Chloe J. McGovern"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
    code_folding: show
    theme: spacelab
    highlight: pygments
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
      toc_depth: 3
  keep_md: true  
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      #Send figures generated in this file to the folder below (use absolute pathway)
                      fig.path = "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/figures/01_QualityTrimming/") 
```


#Setting up the Environment

```{r set-seed}
set.seed(25367)

```

#Timing of Script
```{r time}
start_time <- Sys.time()
start_time
```


#Load Outputs
```{r load}
#install.packages("DT")
pacman::p_load(tidyverse, dada2, phyloseq, patchwork, DT, devtools, install = FALSE)
```

#Reading Raw Sequencing Files
```{r read}
#Path to the fastq files
raw_fastqs_path <- "/local/workdir/cjm423/milk-cheese-analysis/Milk-Cheese-Analysis/data/cheese-fastq-gz"
raw_fastqs_path
#Intuition check
head(list.files(raw_fastqs_path))

# How many files are there? 
length(list.files(raw_fastqs_path))

#Vector of forward reads
#Changed to _R1 from the class data set because that is the pattern that it follows
forward_reads <- list.files(raw_fastqs_path, pattern = "_1.fastq.gz", full.names = TRUE)  

#Intuition check
head(forward_reads)

#Intuition check 2
stopifnot(length(forward_reads) < length(list.files(raw_fastqs_path)))

#Vector reverse reads
reverse_reads <- list.files(raw_fastqs_path, pattern = "_2.fastq.gz", full.names = TRUE)

#Intuition check
head(reverse_reads)

#Intuition check 2
stopifnot(length(reverse_reads) == length(forward_reads))
```

##Assess Raw Read Quality
#Evaluate Raw Sequence Quality

#Plot 12 random samples of plots
```{r raw-quality}
# Randomly select 12 samples from dataset to evaluate 
random_samples <- sample(1:length(reverse_reads), size = 12)
random_samples

# Calculate and plot quality of these two samples
forward_filteredQual_plot_12 <- plotQualityProfile(forward_reads[random_samples]) + 
  labs(title = "Forward Read: Raw Quality")

reverse_filteredQual_plot_12 <- plotQualityProfile(reverse_reads[random_samples]) + 
  labs(title = "Reverse Read: Raw Quality")

# Plot them together with patchwork
forward_filteredQual_plot_12 + reverse_filteredQual_plot_12
```

##Aggregated Raw Quality Plots

```{r aggregate-raw-qc}
# Aggregate all QC plots 
# Forward reads
forward_preQC_plot <- 
  plotQualityProfile(forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Pre-QC")

# Reverse reads
reverse_preQC_plot <- 
  plotQualityProfile(reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Pre-QC")

# Put the two plots together
preQC_aggregate_plot <- 
  forward_preQC_plot + reverse_preQC_plot

# Show the plot
preQC_aggregate_plot
```

##Interpertation 1: 

There is a decline in reads after 100 cycles/bases for the forward and reverse reads. This data resembles older Illumina sequencing runs with a dramatic dive in quality towards the end of the run.

The start of the run has a small dip around basepair 7 for both the forward and reverse runs. 

There are a good amount of reads (in terms of numbers, over one million for both the forward and reverse). There are over a million for the 12 samples so there are lots of basepairs to use for sequencing and may also provide cushion for trimming the sequences to be shorter for better quality. 

##Prepare a placeholder for filtered reads
```{r, pre-filter}
# Create vector of sample names from the file names 
sample_names <- sapply(strsplit(basename(forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)
```

```{r, placeholder}
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"
filtered_fastqs_path

# Create 2 vectors: filtered_forward_reads & filtered_reverse_reads
#Filtered Forward
filtered_forward_reads <- 
  file.path(filtered_fastqs_path, paste0(sample_names, "_R1_filtered.fastq.gz"))

# Intuition Check 
length(filtered_forward_reads)

#Filtered Reverse
filtered_reverse_reads <- 
  file.path(filtered_fastqs_path, paste0(sample_names, "_R2_filtered.fastq.gz"))

#Intuition Check
head(filtered_reverse_reads)
length(filtered_reverse_reads)
```

This step looks good! Yay!

##Filter and Trim Reads
```{r filter-and-trim}

#Paired
filtered_reads <- filterAndTrim(forward_reads, filtered_forward_reads,
              reverse_reads, filtered_reverse_reads,
              truncLen = c(185,185), trimLeft = c(19,20),
              maxN = 0, maxEE = c(1,1), truncQ = 2, 
              rm.phix = TRUE, compress = TRUE, 
              multithread = 8)

```

I chose these parameters for a few reasons. In the manuscript I am following, they did their expected error to be 2, trimmed the bps to 240, and did not specify any bioinformatics work with primers. Thank fully they used standard V4 primers of 515-806 bps. The Earth Microbiome project provided the reference primers base pairs. I was able to see that they did sequence the primers and cut them out in their analysis. 

Additionally, in the MultiQC and pre-qc plots generated in this analysis, showed that there is a significant amount of reads at the end of both the forward and reverse runs that a significant decrease in quality is observed. For the sake of this assignment, I decided to be rigid in the analysis with an EE of 1 and trimming base pairs where there is an overall trend of decreasing quality score (phraed <20) and if later I was too strict in the cut off, I can always redo the analysis. 

Update, my initial parameters were too strict, I only had about a 3.5% retention rate in sequences so I decided to change TrunQ to 2 instead of 20, my truncLen to 220 bps to try to cut out some of the rough ending base pairs (hopefully not cutting out the overlap region, but I can always adjust if needed).  

Another update, after looking at the histogram of percentage of sequences retained, I deicded to truncate the sequence length to 185 bps to increase the overall percentage of base pairs retained. 


##Assess Trimmed Read Quality
```{r evaluate-trimmed bacteria}
# Plot the 12 random samples after QC
forward_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_forward_reads[random_samples]) + 
  labs(title = "Trimmed Forward Read Quality")

reverse_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_reverse_reads[random_samples]) + 
  labs(title = "Trimmed Reverse Read Quality")

# Put the two plots together 
forward_filteredQual_plot_12 + reverse_filteredQual_plot_12
```


##Aggregated Trimmed Plots
```{r aggregate-plots}
# Aggregate all QC plots 
# Forward reads
forward_postQC_plot <- 
  plotQualityProfile(filtered_forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Post-QC")

# reverse reads
reverse_postQC_plot <- 
  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Post-QC")

# Now, let's put the two plots together
postQC_aggregate_plot <- 
  # Plot the forward and reverse together 
  forward_postQC_plot + reverse_postQC_plot
# Show the plot
postQC_aggregate_plot
```

#Interpertation 2:

This post-QC quality score plot from 20 aggregated Illumina sequencing files shows the forward (left) and reverse (right) reads after quality filtering and trimming. Unfortunately, this data is not as high-quality as hoped for with from phraed scores dropping below desirable values around 130 basepairs. Around 165 basepairs, the phraed scores drop below 20, but there are concerns about the forward and reverse reads overlapping. This may be the best I can do for now in my trimming and filtering of this Brazilian cheese data set. 

To further confirm that this dataset is filtered and trimmed appropriately, let’s take a look at the read retention of our QC step...

##Read Retention Post-QC
```{r read-retention}
# Make output into dataframe 
filtered_df <- as.data.frame(filtered_reads) %>%
  mutate(percent.retained = reads.out/reads.in)

# Intuition check
# Visualize it in table format 
DT::datatable(filtered_df)

# Let's calculate some statistics
read_stats_df <- 
  filtered_df %>%
  reframe(median_reads_in = median(reads.in),
          median_reads_out = median(reads.out),
          median_percent_retained = (median(reads.out)/median(reads.in)),
          max_percent_retained = max(reads.out/reads.in),
          min_percent_retained = min(reads.out/reads.in))

# Take a look at it!
read_stats_df

# Plot it 
numSeqs_QC_dotplot <-
  filtered_df %>%
  ggplot(aes(x = reads.in, y = reads.out)) + 
  geom_point(alpha = 0.5, size = 2) + 
  labs(x = "# of Raw Seqs", 
       y = "# of Seqs Retained") + 
  # Now let's add a 1:1 line for reference of keeping 100% of the reads
  geom_abline(slope=1, intercept = 0, color = "deeppink")

# Now, let's look at the number of reads retained in a histogram
numRetained_QC_histplot <- 
  filtered_df %>%
  ggplot(aes(x = reads.out)) + 
  geom_histogram() + 
  labs(x = "# of Seqs Retained", 
       y = "# of Samples") 

# Create a histogram of percent reads retained in a histogram
percSeqs_QC_histplot <- 
  filtered_df %>%
  ggplot(aes(x = percent.retained)) + 
  geom_histogram() + 
  labs(x = "% of Seqs Retained", 
       y = "# of Samples") + 
  # Set the scale to be between 0-1 (0-100%)
  scale_x_continuous(limits = c(0, 1))

# Now, let's put the plots together
numSeqs_QC_dotplot + numRetained_QC_histplot + percSeqs_QC_histplot + 
  plot_annotation(tag_levels = 'A')
```

#Interpertation 3: 

This figure presents three panels showing how many sequences were retained after quality filtering and trimming in the DADA2 pipeline. Let’s break down each panel:

#   Panel A: Scatter Plot of Raw vs. Retained Sequences:

Let's break down what we are looking at in Panel A. 

  X-axis: Number of raw sequences before filtering.
  Y-axis: Number of sequences retained after filtering.
  Pink Line: The diagonal line represents perfect retention (i.e., no sequences lost).
    
Most points fall below the line, indicating that a many samples lost sequences during filtering. Minor losses are normal due to quality filtering. The closeness of the points also improved as I truncated the sequence langth to 185 down from 240 bps. 

#   Panel B: Histogram of the Number of Sequences Retained per Sample

In Panel B;

  X-axis: Number of sequences retained per sample.
  Y-axis: Number of samples with that many retained sequences.

There seems to be a relative normal distribution of the number of sequences retained from 3,000 to 11,000 sequences. This indicates consistency in overall quality read. 

#   Panel C: Histogram of Percent of Sequences Retained

Lastly, in Panel C, we have...

  X-axis: Proportion (%) of sequences retained per sample.
  Y-axis: Number of samples at each proportion.

Looking at the histogram, we have a consistent 75% retention rate in sequences. Since the quality score is already set quite low, and the truncation of the forward and reverse read sequences is trimmed for the primer length, per the Earth Microbiome Project. 

Interestingly, the higher the sequence length, the less percentage of sequences retained. Whereas, when I made the sequence length less, to 185, the retention of sequences increased. While 75% data retention is not 90-100%, I feel confident in the filtering and trimming parameters that the data set is as clean as it can be wile maintaining the integrity of the raw data set. 

##Visualize QC differences in plot
```{r qc-differences}
# Plot the pre and post together in one plot
preQC_aggregate_plot / postQC_aggregate_plot
```

#Interpertation 4: 

This figure is comparing your pre-QC to your post-QC read quality. Here, in this location of your analyses, please insert a description of the interpretation you draw from yor overall quality control results. 

Forward: The forward reads post-QC appear to be higher quality. There are less dips in phraed scores in the middle of the run, which shows that the QC worked! 

Reverse: The reverse reads still have a significant amount of dips. However, the end of the reverse read does appear to have improved through filtering. 

Overall, it is normal for the end of the reads to decline in quality, but I would say overall, the filtering step did it's job and cleaned the data set appropriately to continue on in the sequencing bioinformatics. 

#Final Steps
```{r}
#Check render time
end_time <- Sys.time()
end_time 

elapsed_time <- round((end_time - start_time), 3)
elapsed_time

#Ensure reproducibility
devtools::session_info()
```

